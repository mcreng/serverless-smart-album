from sys import platform

import pandas as pd
from models import *
from utils.datasets import *
from utils.utils import *
from config import opt


# Initialize
device = torch_utils.select_device(opt.device)

# Initialize model
model = Darknet(opt.cfg, opt.img_size)

# Load weights
_ = load_darknet_weights(model, opt.weights)

# Change to eval mode
model.to(device).eval()

# Half precision (only supported on CUDA)
half = opt.half and device.type != 'cpu'
if half:
    model.half()


def detect(images):
    """
    Detect objects in images.

    Params:
        images (list): List of images in np.ndarray.

    Returns:
        preds (list): List of list. Each list is generated by one image, and in it stores dictionaries which each represents one object. In each dictionary, x1, y1, x2, y2 (int) specify the bounding box of the detected object, conf (float) specifies the confidence level of the detection and class (str) specifies the object class.
    """
    # Set Dataloader
    dataset = LoadImages(images, img_size=opt.img_size, half=half)

    # Get classes and colors
    classes = load_classes(parse_data_cfg(opt.data)['names'])
    colors = [[random.randint(0, 255) for _ in range(3)]
              for _ in range(len(classes))]

    # Run inference
    preds = []
    for path, img, im0s, vid_cap in dataset:

        # Get detections
        img = torch.from_numpy(img).to(device)
        if img.ndimension() == 3:
            img = img.unsqueeze(0)
        pred = model(img)[0]

        if half:
            pred = pred.float()

        # Apply NMS
        pred = non_max_suppression(pred, opt.conf_thres, opt.nms_thres)

        # Process detections
        for i, det in enumerate(pred):  # detections per image
            if det is not None and len(det):
                # Rescale boxes from img_size to im0 size
                det[:, :4] = scale_coords(
                    img.shape[2:], det[:, :4], im0s.shape).round()

        # Convert prediction output to dictionary
        df = pd.DataFrame \
            .from_records(pred[0].numpy(), columns=['x1', 'y1', 'x2', 'y2', 'conf', 'unk', 'class']) \
            .drop(columns=['unk']) \
            .astype(dtype={'x1': 'int', 'y1': 'int', 'x2': 'int', 'y2': 'int'})
        df['class'] = df['class'].map(lambda c: classes[int(c)])
        preds.append(df.to_dict(orient='records'))

    return preds
